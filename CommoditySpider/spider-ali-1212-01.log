2018-12-12 14:05:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: CommoditySpider)
2018-12-12 14:05:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.1 (v3.7.1:260ec2c36a, Oct 20 2018, 14:05:16) [MSC v.1915 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Windows-10-10.0.17763-SP0
2018-12-12 14:05:27 [scrapy.crawler] INFO: Overridden settings: {'AJAXCRAWL_ENABLED': True, 'AUTOTHROTTLE_ENABLED': True, 'AUTOTHROTTLE_MAX_DELAY': 30, 'AUTOTHROTTLE_START_DELAY': 0.1, 'AUTOTHROTTLE_TARGET_CONCURRENCY': 128, 'BOT_NAME': 'CommoditySpider', 'COMMANDS_MODULE': 'CommoditySpider.commands', 'CONCURRENT_REQUESTS': 256, 'CONCURRENT_REQUESTS_PER_DOMAIN': 256, 'CONCURRENT_REQUESTS_PER_IP': 256, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 0.1, 'DOWNLOAD_TIMEOUT': 30, 'LOG_FILE': 'spider-ali-1212-01.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CommoditySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['CommoditySpider.spiders'], 'TELNETCONSOLE_ENABLED': False}
2018-12-12 14:05:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState',
 'scrapy.extensions.throttle.AutoThrottle']
2018-12-12 14:05:27 [py.warnings] WARNING: d:\program files\python3.7.1\lib\site-packages\scrapy\utils\deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2018-12-12 14:05:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'CommoditySpider.middlewares.RandomUserAgentMiddleware',
 'CommoditySpider.middlewares.CommodityspiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-12 14:05:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-12 14:05:28 [py.warnings] WARNING: D:\Py-projects\CommoditySpider\CommoditySpider\pipelines.py:10: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2018-12-12 14:05:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CommoditySpider.pipelines.CommodityspiderPipeline']
2018-12-12 14:05:28 [scrapy.core.engine] INFO: Spider opened
2018-12-12 14:05:28 [root] INFO: ---Opened spider = aliexpress
2018-12-12 14:05:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-12 14:05:28 [aliexpress] INFO: Spider opened: aliexpress
2018-12-12 14:05:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.aliexpress.com/category/205775202/special-categories.html?g=y> (referer: https://www.aliexpress.com/all-wholesale-products.html)
Traceback (most recent call last):
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Py-projects\CommoditySpider\CommoditySpider\spiders\aliexpress.py", line 107, in parse_page
    li_tags = ul_tag.find_all('li')
AttributeError: 'NoneType' object has no attribute 'find_all'
2018-12-12 14:06:28 [scrapy.extensions.logstats] INFO: Crawled 95 pages (at 95 pages/min), scraped 2182 items (at 2182 items/min)
2018-12-12 14:07:28 [scrapy.extensions.logstats] INFO: Crawled 396 pages (at 301 pages/min), scraped 7512 items (at 5330 items/min)
2018-12-12 14:08:28 [scrapy.extensions.logstats] INFO: Crawled 683 pages (at 287 pages/min), scraped 13002 items (at 5490 items/min)
2018-12-12 14:09:28 [scrapy.extensions.logstats] INFO: Crawled 1045 pages (at 362 pages/min), scraped 17854 items (at 4852 items/min)
2018-12-12 14:10:28 [scrapy.extensions.logstats] INFO: Crawled 1499 pages (at 454 pages/min), scraped 23965 items (at 6111 items/min)
2018-12-12 14:11:28 [scrapy.extensions.logstats] INFO: Crawled 1905 pages (at 406 pages/min), scraped 28198 items (at 4233 items/min)
2018-12-12 14:12:28 [scrapy.extensions.logstats] INFO: Crawled 2334 pages (at 429 pages/min), scraped 29291 items (at 1093 items/min)
2018-12-12 14:13:28 [scrapy.extensions.logstats] INFO: Crawled 2827 pages (at 493 pages/min), scraped 29485 items (at 194 items/min)
2018-12-12 14:14:28 [scrapy.extensions.logstats] INFO: Crawled 3317 pages (at 490 pages/min), scraped 29796 items (at 311 items/min)
2018-12-12 14:15:28 [scrapy.extensions.logstats] INFO: Crawled 3683 pages (at 366 pages/min), scraped 31557 items (at 1761 items/min)
2018-12-12 14:16:28 [scrapy.extensions.logstats] INFO: Crawled 4004 pages (at 321 pages/min), scraped 35934 items (at 4377 items/min)
2018-12-12 14:17:28 [scrapy.extensions.logstats] INFO: Crawled 4332 pages (at 328 pages/min), scraped 40571 items (at 4637 items/min)
2018-12-12 14:18:28 [scrapy.extensions.logstats] INFO: Crawled 4686 pages (at 354 pages/min), scraped 44561 items (at 3990 items/min)
2018-12-12 14:19:28 [scrapy.extensions.logstats] INFO: Crawled 5108 pages (at 422 pages/min), scraped 47149 items (at 2588 items/min)
2018-12-12 14:20:28 [scrapy.extensions.logstats] INFO: Crawled 5554 pages (at 446 pages/min), scraped 48682 items (at 1533 items/min)
2018-12-12 14:21:28 [scrapy.extensions.logstats] INFO: Crawled 6039 pages (at 485 pages/min), scraped 50010 items (at 1328 items/min)
2018-12-12 14:22:28 [scrapy.extensions.logstats] INFO: Crawled 6454 pages (at 415 pages/min), scraped 52376 items (at 2366 items/min)
2018-12-12 14:23:28 [scrapy.extensions.logstats] INFO: Crawled 6827 pages (at 373 pages/min), scraped 58020 items (at 5644 items/min)
2018-12-12 14:24:28 [scrapy.extensions.logstats] INFO: Crawled 7176 pages (at 349 pages/min), scraped 63267 items (at 5247 items/min)
2018-12-12 14:25:28 [scrapy.extensions.logstats] INFO: Crawled 7483 pages (at 307 pages/min), scraped 67872 items (at 4605 items/min)
2018-12-12 14:26:28 [scrapy.extensions.logstats] INFO: Crawled 7847 pages (at 364 pages/min), scraped 73085 items (at 5213 items/min)
2018-12-12 14:27:28 [scrapy.extensions.logstats] INFO: Crawled 8178 pages (at 331 pages/min), scraped 77857 items (at 4772 items/min)
2018-12-12 14:28:28 [scrapy.extensions.logstats] INFO: Crawled 8523 pages (at 345 pages/min), scraped 82766 items (at 4909 items/min)
2018-12-12 14:29:28 [scrapy.extensions.logstats] INFO: Crawled 8923 pages (at 400 pages/min), scraped 87726 items (at 4960 items/min)
2018-12-12 14:30:28 [scrapy.extensions.logstats] INFO: Crawled 9390 pages (at 467 pages/min), scraped 93560 items (at 5834 items/min)
2018-12-12 14:31:28 [scrapy.extensions.logstats] INFO: Crawled 9839 pages (at 449 pages/min), scraped 100138 items (at 6578 items/min)
2018-12-12 14:32:28 [scrapy.extensions.logstats] INFO: Crawled 10266 pages (at 427 pages/min), scraped 106240 items (at 6102 items/min)
2018-12-12 14:33:28 [scrapy.extensions.logstats] INFO: Crawled 10734 pages (at 468 pages/min), scraped 112235 items (at 5995 items/min)
2018-12-12 14:34:28 [scrapy.extensions.logstats] INFO: Crawled 11208 pages (at 474 pages/min), scraped 118635 items (at 6400 items/min)
2018-12-12 14:35:28 [scrapy.extensions.logstats] INFO: Crawled 11637 pages (at 429 pages/min), scraped 125255 items (at 6620 items/min)
2018-12-12 14:36:28 [scrapy.extensions.logstats] INFO: Crawled 11942 pages (at 305 pages/min), scraped 131036 items (at 5781 items/min)
2018-12-12 14:37:28 [scrapy.extensions.logstats] INFO: Crawled 12305 pages (at 363 pages/min), scraped 136872 items (at 5836 items/min)
2018-12-12 14:38:28 [scrapy.extensions.logstats] INFO: Crawled 12656 pages (at 351 pages/min), scraped 141759 items (at 4887 items/min)
2018-12-12 14:39:28 [scrapy.extensions.logstats] INFO: Crawled 13005 pages (at 349 pages/min), scraped 146001 items (at 4242 items/min)
2018-12-12 14:40:28 [scrapy.extensions.logstats] INFO: Crawled 13344 pages (at 339 pages/min), scraped 149196 items (at 3195 items/min)
2018-12-12 14:41:28 [scrapy.extensions.logstats] INFO: Crawled 13742 pages (at 398 pages/min), scraped 152992 items (at 3796 items/min)
2018-12-12 14:42:28 [scrapy.extensions.logstats] INFO: Crawled 14185 pages (at 443 pages/min), scraped 155439 items (at 2447 items/min)
2018-12-12 14:43:28 [scrapy.extensions.logstats] INFO: Crawled 14662 pages (at 477 pages/min), scraped 157407 items (at 1968 items/min)
2018-12-12 14:44:28 [scrapy.extensions.logstats] INFO: Crawled 15101 pages (at 439 pages/min), scraped 160316 items (at 2909 items/min)
2018-12-12 14:45:28 [scrapy.extensions.logstats] INFO: Crawled 15571 pages (at 470 pages/min), scraped 164683 items (at 4367 items/min)
2018-12-12 14:46:28 [scrapy.extensions.logstats] INFO: Crawled 16030 pages (at 459 pages/min), scraped 170714 items (at 6031 items/min)
2018-12-12 14:47:28 [scrapy.extensions.logstats] INFO: Crawled 16357 pages (at 327 pages/min), scraped 176591 items (at 5877 items/min)
2018-12-12 14:48:28 [scrapy.extensions.logstats] INFO: Crawled 16743 pages (at 386 pages/min), scraped 183702 items (at 7111 items/min)
2018-12-12 14:49:28 [scrapy.extensions.logstats] INFO: Crawled 17110 pages (at 367 pages/min), scraped 189753 items (at 6051 items/min)
2018-12-12 14:50:28 [scrapy.extensions.logstats] INFO: Crawled 17490 pages (at 380 pages/min), scraped 195537 items (at 5784 items/min)
2018-12-12 14:51:28 [scrapy.extensions.logstats] INFO: Crawled 17910 pages (at 420 pages/min), scraped 201504 items (at 5967 items/min)
2018-12-12 14:52:28 [scrapy.extensions.logstats] INFO: Crawled 18318 pages (at 408 pages/min), scraped 206837 items (at 5333 items/min)
2018-12-12 14:53:28 [scrapy.extensions.logstats] INFO: Crawled 18722 pages (at 404 pages/min), scraped 212360 items (at 5523 items/min)
2018-12-12 14:54:28 [scrapy.extensions.logstats] INFO: Crawled 19142 pages (at 420 pages/min), scraped 217371 items (at 5011 items/min)
2018-12-12 14:55:28 [scrapy.extensions.logstats] INFO: Crawled 19606 pages (at 464 pages/min), scraped 222315 items (at 4944 items/min)
2018-12-12 14:56:28 [scrapy.extensions.logstats] INFO: Crawled 20047 pages (at 441 pages/min), scraped 227683 items (at 5368 items/min)
2018-12-12 14:57:28 [scrapy.extensions.logstats] INFO: Crawled 20523 pages (at 476 pages/min), scraped 233178 items (at 5495 items/min)
2018-12-12 14:58:28 [scrapy.extensions.logstats] INFO: Crawled 21005 pages (at 482 pages/min), scraped 240286 items (at 7108 items/min)
2018-12-12 14:59:28 [scrapy.extensions.logstats] INFO: Crawled 21383 pages (at 378 pages/min), scraped 246459 items (at 6173 items/min)
2018-12-12 15:00:28 [scrapy.extensions.logstats] INFO: Crawled 21700 pages (at 317 pages/min), scraped 252013 items (at 5554 items/min)
2018-12-12 15:01:28 [scrapy.extensions.logstats] INFO: Crawled 22005 pages (at 305 pages/min), scraped 257089 items (at 5076 items/min)
2018-12-12 15:02:28 [scrapy.extensions.logstats] INFO: Crawled 22448 pages (at 443 pages/min), scraped 261317 items (at 4228 items/min)
2018-12-12 15:02:34 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2018-12-12 15:02:34 [scrapy.core.engine] INFO: Closing spider (shutdown)
2018-12-12 15:02:34 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2018-12-12 15:21:38 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: CommoditySpider)
2018-12-12 15:21:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.1 (v3.7.1:260ec2c36a, Oct 20 2018, 14:05:16) [MSC v.1915 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Windows-10-10.0.17763-SP0
2018-12-12 15:21:38 [scrapy.crawler] INFO: Overridden settings: {'AJAXCRAWL_ENABLED': True, 'AUTOTHROTTLE_ENABLED': True, 'AUTOTHROTTLE_MAX_DELAY': 30, 'AUTOTHROTTLE_START_DELAY': 0.1, 'AUTOTHROTTLE_TARGET_CONCURRENCY': 128, 'BOT_NAME': 'CommoditySpider', 'COMMANDS_MODULE': 'CommoditySpider.commands', 'CONCURRENT_REQUESTS': 256, 'CONCURRENT_REQUESTS_PER_DOMAIN': 256, 'CONCURRENT_REQUESTS_PER_IP': 256, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 0.1, 'DOWNLOAD_TIMEOUT': 30, 'LOG_FILE': 'spider-ali-1212-01.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CommoditySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['CommoditySpider.spiders'], 'TELNETCONSOLE_ENABLED': False}
2018-12-12 15:21:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState',
 'scrapy.extensions.throttle.AutoThrottle']
2018-12-12 15:21:38 [py.warnings] WARNING: d:\program files\python3.7.1\lib\site-packages\scrapy\utils\deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2018-12-12 15:21:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'CommoditySpider.middlewares.RandomUserAgentMiddleware',
 'CommoditySpider.middlewares.CommodityspiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-12 15:21:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-12 15:21:39 [py.warnings] WARNING: D:\Py-projects\CommoditySpider\CommoditySpider\pipelines.py:10: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2018-12-12 15:21:39 [scrapy.middleware] INFO: Enabled item pipelines:
['CommoditySpider.pipelines.CommodityspiderPipeline']
2018-12-12 15:21:39 [scrapy.core.engine] INFO: Spider opened
2018-12-12 15:21:39 [root] INFO: ---Opened spider = aliexpress
2018-12-12 15:21:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-12 15:21:39 [aliexpress] INFO: Spider opened: aliexpress
2018-12-12 15:21:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.aliexpress.com/category/205775202/special-categories.html?g=y> (referer: https://www.aliexpress.com/all-wholesale-products.html)
Traceback (most recent call last):
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Py-projects\CommoditySpider\CommoditySpider\spiders\aliexpress.py", line 107, in parse_page
    li_tags = ul_tag.find_all('li')
AttributeError: 'NoneType' object has no attribute 'find_all'
2018-12-12 15:22:39 [scrapy.extensions.logstats] INFO: Crawled 180 pages (at 180 pages/min), scraped 3748 items (at 3748 items/min)
2018-12-12 15:23:39 [scrapy.extensions.logstats] INFO: Crawled 480 pages (at 300 pages/min), scraped 9858 items (at 6110 items/min)
2018-12-12 15:24:39 [scrapy.extensions.logstats] INFO: Crawled 783 pages (at 303 pages/min), scraped 15924 items (at 6066 items/min)
2018-12-12 15:25:39 [scrapy.extensions.logstats] INFO: Crawled 1122 pages (at 339 pages/min), scraped 22332 items (at 6408 items/min)
2018-12-12 15:26:39 [scrapy.extensions.logstats] INFO: Crawled 1516 pages (at 394 pages/min), scraped 29579 items (at 7247 items/min)
2018-12-12 15:27:39 [scrapy.extensions.logstats] INFO: Crawled 1782 pages (at 266 pages/min), scraped 35001 items (at 5422 items/min)
2018-12-12 15:28:39 [scrapy.extensions.logstats] INFO: Crawled 2078 pages (at 296 pages/min), scraped 41025 items (at 6024 items/min)
2018-12-12 15:29:39 [scrapy.extensions.logstats] INFO: Crawled 2355 pages (at 277 pages/min), scraped 46786 items (at 5761 items/min)
2018-12-12 15:30:39 [scrapy.extensions.logstats] INFO: Crawled 2668 pages (at 313 pages/min), scraped 53048 items (at 6262 items/min)
2018-12-12 15:31:39 [scrapy.extensions.logstats] INFO: Crawled 2987 pages (at 319 pages/min), scraped 59424 items (at 6376 items/min)
2018-12-12 15:32:39 [scrapy.extensions.logstats] INFO: Crawled 3306 pages (at 319 pages/min), scraped 65682 items (at 6258 items/min)
2018-12-12 15:33:39 [scrapy.extensions.logstats] INFO: Crawled 3674 pages (at 368 pages/min), scraped 72504 items (at 6822 items/min)
2018-12-12 15:34:39 [scrapy.extensions.logstats] INFO: Crawled 4097 pages (at 423 pages/min), scraped 80222 items (at 7718 items/min)
2018-12-12 15:35:39 [scrapy.extensions.logstats] INFO: Crawled 4486 pages (at 389 pages/min), scraped 87896 items (at 7674 items/min)
2018-12-12 15:36:39 [scrapy.extensions.logstats] INFO: Crawled 4820 pages (at 334 pages/min), scraped 94825 items (at 6929 items/min)
2018-12-12 15:37:39 [scrapy.extensions.logstats] INFO: Crawled 5123 pages (at 303 pages/min), scraped 101162 items (at 6337 items/min)
2018-12-12 15:38:39 [scrapy.extensions.logstats] INFO: Crawled 5445 pages (at 322 pages/min), scraped 107909 items (at 6747 items/min)
2018-12-12 15:39:39 [scrapy.extensions.logstats] INFO: Crawled 5745 pages (at 300 pages/min), scraped 114139 items (at 6230 items/min)
2018-12-12 15:40:39 [scrapy.extensions.logstats] INFO: Crawled 6045 pages (at 300 pages/min), scraped 120406 items (at 6267 items/min)
2018-12-12 15:41:39 [scrapy.extensions.logstats] INFO: Crawled 6373 pages (at 328 pages/min), scraped 127267 items (at 6861 items/min)
2018-12-12 15:42:39 [scrapy.extensions.logstats] INFO: Crawled 6674 pages (at 301 pages/min), scraped 133551 items (at 6284 items/min)
2018-12-12 15:43:39 [scrapy.extensions.logstats] INFO: Crawled 6992 pages (at 318 pages/min), scraped 140132 items (at 6581 items/min)
2018-12-12 15:44:39 [scrapy.extensions.logstats] INFO: Crawled 7424 pages (at 432 pages/min), scraped 148759 items (at 8627 items/min)
2018-12-12 15:45:39 [scrapy.extensions.logstats] INFO: Crawled 7839 pages (at 415 pages/min), scraped 157058 items (at 8299 items/min)
2018-12-12 15:46:39 [scrapy.extensions.logstats] INFO: Crawled 8273 pages (at 434 pages/min), scraped 165683 items (at 8625 items/min)
2018-12-12 15:47:39 [scrapy.extensions.logstats] INFO: Crawled 8622 pages (at 349 pages/min), scraped 172965 items (at 7282 items/min)
2018-12-12 15:48:39 [scrapy.extensions.logstats] INFO: Crawled 8919 pages (at 297 pages/min), scraped 179112 items (at 6147 items/min)
2018-12-12 15:49:39 [scrapy.extensions.logstats] INFO: Crawled 9241 pages (at 322 pages/min), scraped 185729 items (at 6617 items/min)
2018-12-12 15:50:39 [scrapy.extensions.logstats] INFO: Crawled 9526 pages (at 285 pages/min), scraped 191584 items (at 5855 items/min)
2018-12-12 15:51:39 [scrapy.extensions.logstats] INFO: Crawled 9935 pages (at 409 pages/min), scraped 199530 items (at 7946 items/min)
2018-12-12 15:52:39 [scrapy.extensions.logstats] INFO: Crawled 10302 pages (at 367 pages/min), scraped 206955 items (at 7425 items/min)
2018-12-12 15:53:39 [scrapy.extensions.logstats] INFO: Crawled 10670 pages (at 368 pages/min), scraped 214511 items (at 7556 items/min)
2018-12-12 15:54:39 [scrapy.extensions.logstats] INFO: Crawled 11074 pages (at 404 pages/min), scraped 221203 items (at 6692 items/min)
2018-12-12 15:55:39 [scrapy.extensions.logstats] INFO: Crawled 11512 pages (at 438 pages/min), scraped 226979 items (at 5776 items/min)
2018-12-12 15:56:39 [scrapy.extensions.logstats] INFO: Crawled 11958 pages (at 446 pages/min), scraped 231363 items (at 4384 items/min)
2018-12-12 15:57:39 [scrapy.extensions.logstats] INFO: Crawled 12409 pages (at 451 pages/min), scraped 234522 items (at 3159 items/min)
2018-12-12 15:58:39 [scrapy.extensions.logstats] INFO: Crawled 12894 pages (at 485 pages/min), scraped 236281 items (at 1759 items/min)
2018-12-12 15:59:39 [scrapy.extensions.logstats] INFO: Crawled 13376 pages (at 482 pages/min), scraped 238337 items (at 2056 items/min)
2018-12-12 16:00:39 [scrapy.extensions.logstats] INFO: Crawled 13853 pages (at 477 pages/min), scraped 241551 items (at 3214 items/min)
2018-12-12 16:01:39 [scrapy.extensions.logstats] INFO: Crawled 14335 pages (at 482 pages/min), scraped 245942 items (at 4391 items/min)
2018-12-12 16:02:39 [scrapy.extensions.logstats] INFO: Crawled 14816 pages (at 481 pages/min), scraped 252043 items (at 6101 items/min)
2018-12-12 16:03:39 [scrapy.extensions.logstats] INFO: Crawled 15265 pages (at 449 pages/min), scraped 259535 items (at 7492 items/min)
2018-12-12 16:04:39 [scrapy.extensions.logstats] INFO: Crawled 15661 pages (at 396 pages/min), scraped 266250 items (at 6715 items/min)
2018-12-12 16:05:39 [scrapy.extensions.logstats] INFO: Crawled 16091 pages (at 430 pages/min), scraped 269557 items (at 3307 items/min)
2018-12-12 16:06:39 [scrapy.extensions.logstats] INFO: Crawled 16522 pages (at 431 pages/min), scraped 271629 items (at 2072 items/min)
2018-12-12 16:07:39 [scrapy.extensions.logstats] INFO: Crawled 16971 pages (at 449 pages/min), scraped 273500 items (at 1871 items/min)
2018-12-12 16:08:39 [scrapy.extensions.logstats] INFO: Crawled 17446 pages (at 475 pages/min), scraped 274623 items (at 1123 items/min)
2018-12-12 16:09:39 [scrapy.extensions.logstats] INFO: Crawled 17936 pages (at 490 pages/min), scraped 275033 items (at 410 items/min)
2018-12-12 16:10:39 [scrapy.extensions.logstats] INFO: Crawled 18421 pages (at 485 pages/min), scraped 275672 items (at 639 items/min)
2018-12-12 16:11:39 [scrapy.extensions.logstats] INFO: Crawled 18909 pages (at 488 pages/min), scraped 276782 items (at 1110 items/min)
2018-12-12 16:12:39 [scrapy.extensions.logstats] INFO: Crawled 19399 pages (at 490 pages/min), scraped 278291 items (at 1509 items/min)
2018-12-12 16:13:39 [scrapy.extensions.logstats] INFO: Crawled 19873 pages (at 474 pages/min), scraped 281231 items (at 2940 items/min)
2018-12-12 16:14:39 [scrapy.extensions.logstats] INFO: Crawled 20224 pages (at 351 pages/min), scraped 286166 items (at 4935 items/min)
2018-12-12 16:15:39 [scrapy.extensions.logstats] INFO: Crawled 20585 pages (at 361 pages/min), scraped 293592 items (at 7426 items/min)
2018-12-12 16:16:39 [scrapy.extensions.logstats] INFO: Crawled 21011 pages (at 426 pages/min), scraped 302086 items (at 8494 items/min)
2018-12-12 16:17:39 [scrapy.extensions.logstats] INFO: Crawled 21352 pages (at 341 pages/min), scraped 308765 items (at 6679 items/min)
2018-12-12 16:18:39 [scrapy.extensions.logstats] INFO: Crawled 21691 pages (at 339 pages/min), scraped 315629 items (at 6864 items/min)
2018-12-12 16:19:39 [scrapy.extensions.logstats] INFO: Crawled 22012 pages (at 321 pages/min), scraped 322101 items (at 6472 items/min)
2018-12-12 16:20:39 [scrapy.extensions.logstats] INFO: Crawled 22351 pages (at 339 pages/min), scraped 328819 items (at 6718 items/min)
2018-12-12 16:21:39 [scrapy.extensions.logstats] INFO: Crawled 22673 pages (at 322 pages/min), scraped 335098 items (at 6279 items/min)
2018-12-12 16:22:39 [scrapy.extensions.logstats] INFO: Crawled 23012 pages (at 339 pages/min), scraped 341483 items (at 6385 items/min)
2018-12-12 16:23:39 [scrapy.extensions.logstats] INFO: Crawled 23444 pages (at 432 pages/min), scraped 349413 items (at 7930 items/min)
2018-12-12 16:24:39 [scrapy.extensions.logstats] INFO: Crawled 23867 pages (at 423 pages/min), scraped 357295 items (at 7882 items/min)
2018-12-12 16:25:39 [scrapy.extensions.logstats] INFO: Crawled 24251 pages (at 384 pages/min), scraped 364820 items (at 7525 items/min)
2018-12-12 16:25:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.aliexpress.com/category/200002394/accessories-parts/66.html?site=glo&g=y&needQuery=n&tag=>
Traceback (most recent call last):
  File "d:\program files\python3.7.1\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "d:\program files\python3.7.1\lib\site-packages\twisted\python\failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "d:\program files\python3.7.1\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "d:\program files\python3.7.1\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.aliexpress.com/category/200002394/accessories-parts/66.html?site=glo&g=y&needQuery=n&tag= took longer than 30.0 seconds..
2018-12-12 16:26:39 [scrapy.extensions.logstats] INFO: Crawled 24533 pages (at 282 pages/min), scraped 370460 items (at 5640 items/min)
2018-12-12 16:27:39 [scrapy.extensions.logstats] INFO: Crawled 24819 pages (at 286 pages/min), scraped 376062 items (at 5602 items/min)
2018-12-12 16:28:39 [scrapy.extensions.logstats] INFO: Crawled 25083 pages (at 264 pages/min), scraped 381113 items (at 5051 items/min)
2018-12-12 16:29:39 [scrapy.extensions.logstats] INFO: Crawled 25406 pages (at 323 pages/min), scraped 387194 items (at 6081 items/min)
2018-12-12 16:30:39 [scrapy.extensions.logstats] INFO: Crawled 25767 pages (at 361 pages/min), scraped 393198 items (at 6004 items/min)
2018-12-12 16:31:39 [scrapy.extensions.logstats] INFO: Crawled 26104 pages (at 337 pages/min), scraped 398912 items (at 5714 items/min)
2018-12-12 16:32:39 [scrapy.extensions.logstats] INFO: Crawled 26481 pages (at 377 pages/min), scraped 404826 items (at 5914 items/min)
2018-12-12 16:33:39 [scrapy.extensions.logstats] INFO: Crawled 26887 pages (at 406 pages/min), scraped 410489 items (at 5663 items/min)
2018-12-12 16:34:39 [scrapy.extensions.logstats] INFO: Crawled 27343 pages (at 456 pages/min), scraped 416907 items (at 6418 items/min)
2018-12-12 16:35:39 [scrapy.extensions.logstats] INFO: Crawled 27674 pages (at 331 pages/min), scraped 422725 items (at 5818 items/min)
2018-12-12 16:36:39 [scrapy.extensions.logstats] INFO: Crawled 28004 pages (at 330 pages/min), scraped 429472 items (at 6747 items/min)
2018-12-12 16:37:39 [scrapy.extensions.logstats] INFO: Crawled 28312 pages (at 308 pages/min), scraped 435529 items (at 6057 items/min)
2018-12-12 16:38:39 [scrapy.extensions.logstats] INFO: Crawled 28689 pages (at 377 pages/min), scraped 442736 items (at 7207 items/min)
2018-12-12 16:39:39 [scrapy.extensions.logstats] INFO: Crawled 29124 pages (at 435 pages/min), scraped 450690 items (at 7954 items/min)
2018-12-12 16:40:39 [scrapy.extensions.logstats] INFO: Crawled 29536 pages (at 412 pages/min), scraped 458355 items (at 7665 items/min)
2018-12-12 16:41:39 [scrapy.extensions.logstats] INFO: Crawled 29992 pages (at 456 pages/min), scraped 466292 items (at 7937 items/min)
2018-12-12 16:42:39 [scrapy.extensions.logstats] INFO: Crawled 30410 pages (at 418 pages/min), scraped 473923 items (at 7631 items/min)
2018-12-12 16:43:39 [scrapy.extensions.logstats] INFO: Crawled 30830 pages (at 420 pages/min), scraped 481723 items (at 7800 items/min)
2018-12-12 16:44:39 [scrapy.extensions.logstats] INFO: Crawled 31159 pages (at 329 pages/min), scraped 488036 items (at 6313 items/min)
2018-12-12 16:45:39 [scrapy.extensions.logstats] INFO: Crawled 31511 pages (at 352 pages/min), scraped 494531 items (at 6495 items/min)
2018-12-12 16:46:39 [scrapy.extensions.logstats] INFO: Crawled 31842 pages (at 331 pages/min), scraped 500619 items (at 6088 items/min)
2018-12-12 16:47:39 [scrapy.extensions.logstats] INFO: Crawled 32296 pages (at 454 pages/min), scraped 508449 items (at 7830 items/min)
2018-12-12 16:48:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-12 16:48:34 [root] INFO: ---Closed spider = aliexpress
2018-12-12 16:48:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 58,
 'downloader/exception_type_count/scrapy.core.downloader.handlers.http11.TunnelError': 5,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 53,
 'downloader/request_bytes': 21720352,
 'downloader/request_count': 32648,
 'downloader/request_method_count/GET': 32648,
 'downloader/response_bytes': 89711618,
 'downloader/response_count': 32590,
 'downloader/response_status_count/200': 32589,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 12, 8, 48, 34, 637448),
 'item_scraped_count': 513664,
 'log_count/ERROR': 2,
 'log_count/INFO': 96,
 'log_count/WARNING': 2,
 'request_depth_max': 101,
 'response_received_count': 32590,
 'retry/count': 57,
 'retry/max_reached': 1,
 'retry/reason_count/scrapy.core.downloader.handlers.http11.TunnelError': 5,
 'retry/reason_count/twisted.internet.error.TimeoutError': 52,
 'scheduler/dequeued': 32646,
 'scheduler/dequeued/disk': 32646,
 'scheduler/enqueued': 32646,
 'scheduler/enqueued/disk': 32646,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 12, 12, 7, 21, 39, 213630)}
2018-12-12 16:48:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-13 09:27:57 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: CommoditySpider)
2018-12-13 09:27:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.1 (v3.7.1:260ec2c36a, Oct 20 2018, 14:05:16) [MSC v.1915 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Windows-10-10.0.17763-SP0
2018-12-13 09:27:57 [scrapy.crawler] INFO: Overridden settings: {'AJAXCRAWL_ENABLED': True, 'AUTOTHROTTLE_ENABLED': True, 'AUTOTHROTTLE_MAX_DELAY': 30, 'AUTOTHROTTLE_START_DELAY': 0.1, 'AUTOTHROTTLE_TARGET_CONCURRENCY': 128, 'BOT_NAME': 'CommoditySpider', 'COMMANDS_MODULE': 'CommoditySpider.commands', 'CONCURRENT_REQUESTS': 256, 'CONCURRENT_REQUESTS_PER_DOMAIN': 256, 'CONCURRENT_REQUESTS_PER_IP': 256, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 0.1, 'DOWNLOAD_TIMEOUT': 30, 'LOG_FILE': 'spider-ali-1212-01.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CommoditySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['CommoditySpider.spiders'], 'TELNETCONSOLE_ENABLED': False}
2018-12-13 09:27:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2018-12-13 09:27:57 [py.warnings] WARNING: D:\Program Files\Python3.7.1\lib\site-packages\scrapy\utils\deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2018-12-13 09:27:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'CommoditySpider.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-13 09:27:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-13 09:27:58 [py.warnings] WARNING: D:\Py-projects\CommoditySpider\CommoditySpider\pipelines.py:10: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2018-12-13 09:27:58 [scrapy.middleware] INFO: Enabled item pipelines:
['CommoditySpider.pipelines.CommodityspiderPipeline']
2018-12-13 09:27:58 [scrapy.core.engine] INFO: Spider opened
2018-12-13 09:27:58 [root] INFO: ---Opened spider = aliexpress
2018-12-13 09:27:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-13 09:27:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-13 09:27:59 [root] INFO: ---Closed spider = aliexpress
2018-12-13 09:27:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 799,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 19611,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 13, 1, 27, 59, 429973),
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 12, 13, 1, 27, 58, 407958)}
2018-12-13 09:27:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-13 09:29:08 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: CommoditySpider)
2018-12-13 09:29:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.1 (v3.7.1:260ec2c36a, Oct 20 2018, 14:05:16) [MSC v.1915 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Windows-10-10.0.17763-SP0
2018-12-13 09:29:08 [scrapy.crawler] INFO: Overridden settings: {'AJAXCRAWL_ENABLED': True, 'AUTOTHROTTLE_ENABLED': True, 'AUTOTHROTTLE_MAX_DELAY': 30, 'AUTOTHROTTLE_START_DELAY': 0.1, 'AUTOTHROTTLE_TARGET_CONCURRENCY': 128, 'BOT_NAME': 'CommoditySpider', 'COMMANDS_MODULE': 'CommoditySpider.commands', 'CONCURRENT_REQUESTS': 256, 'CONCURRENT_REQUESTS_PER_DOMAIN': 256, 'CONCURRENT_REQUESTS_PER_IP': 256, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 0.1, 'DOWNLOAD_TIMEOUT': 30, 'LOG_FILE': 'spider-ali-1212-01.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CommoditySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['CommoditySpider.spiders'], 'TELNETCONSOLE_ENABLED': False}
2018-12-13 09:29:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2018-12-13 09:29:09 [py.warnings] WARNING: D:\Program Files\Python3.7.1\lib\site-packages\scrapy\utils\deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2018-12-13 09:29:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'CommoditySpider.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-13 09:29:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-13 09:29:09 [py.warnings] WARNING: D:\Py-projects\CommoditySpider\CommoditySpider\pipelines.py:10: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2018-12-13 09:29:09 [scrapy.middleware] INFO: Enabled item pipelines:
['CommoditySpider.pipelines.CommodityspiderPipeline']
2018-12-13 09:29:09 [scrapy.core.engine] INFO: Spider opened
2018-12-13 09:29:09 [root] INFO: ---Opened spider = aliexpress
2018-12-13 09:29:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-13 09:29:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-13 09:29:10 [root] INFO: ---Closed spider = aliexpress
2018-12-13 09:29:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 1,
 'downloader/request_bytes': 2603,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 21027,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/302': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 13, 1, 29, 10, 785580),
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 13, 1, 29, 9, 842616)}
2018-12-13 09:29:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-12-13 09:29:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: CommoditySpider)
2018-12-13 09:29:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.1 (v3.7.1:260ec2c36a, Oct 20 2018, 14:05:16) [MSC v.1915 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Windows-10-10.0.17763-SP0
2018-12-13 09:29:29 [scrapy.crawler] INFO: Overridden settings: {'AJAXCRAWL_ENABLED': True, 'AUTOTHROTTLE_ENABLED': True, 'AUTOTHROTTLE_MAX_DELAY': 30, 'AUTOTHROTTLE_START_DELAY': 0.1, 'AUTOTHROTTLE_TARGET_CONCURRENCY': 128, 'BOT_NAME': 'CommoditySpider', 'COMMANDS_MODULE': 'CommoditySpider.commands', 'CONCURRENT_REQUESTS': 256, 'CONCURRENT_REQUESTS_PER_DOMAIN': 256, 'CONCURRENT_REQUESTS_PER_IP': 256, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 0.1, 'DOWNLOAD_TIMEOUT': 30, 'LOG_FILE': 'spider-ali-1212-01.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CommoditySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['CommoditySpider.spiders'], 'TELNETCONSOLE_ENABLED': False}
2018-12-13 09:29:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2018-12-13 09:29:29 [py.warnings] WARNING: D:\Program Files\Python3.7.1\lib\site-packages\scrapy\utils\deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2018-12-13 09:29:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'CommoditySpider.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-12-13 09:29:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-12-13 09:29:30 [py.warnings] WARNING: D:\Py-projects\CommoditySpider\CommoditySpider\pipelines.py:10: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2018-12-13 09:29:30 [scrapy.middleware] INFO: Enabled item pipelines:
['CommoditySpider.pipelines.CommodityspiderPipeline']
2018-12-13 09:29:30 [scrapy.core.engine] INFO: Spider opened
2018-12-13 09:29:30 [root] INFO: ---Opened spider = aliexpress
2018-12-13 09:29:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-12-13 09:29:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-12-13 09:29:31 [root] INFO: ---Closed spider = aliexpress
2018-12-13 09:29:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 1,
 'downloader/request_bytes': 2638,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 21020,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/302': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 12, 13, 1, 29, 31, 511874),
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 12, 13, 1, 29, 30, 352221)}
2018-12-13 09:29:31 [scrapy.core.engine] INFO: Spider closed (finished)
